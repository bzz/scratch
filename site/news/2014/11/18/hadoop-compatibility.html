<!DOCTYPE html>
<html lang="en">
    <head>
	    <meta charset="utf-8">
	    <meta http-equiv="X-UA-Compatible" content="IE=edge">
	    <meta name="viewport" content="width=device-width, initial-scale=1">
	    
	    <title>Apache Flink (incubating): Hadoop Compatibility in Flink</title>
	    <link rel="shortcut icon" href="favicon.ico" type="image/x-icon">
	    <link rel="icon" href="favicon.ico" type="image/x-icon">
	    <link rel="stylesheet" href="/css/bootstrap.css">
	    <link rel="stylesheet" href="/css/bootstrap-lumen-custom.css">
	    <link rel="stylesheet" href="/css/syntax.css">
	    <link rel="stylesheet" href="/css/custom.css">
	    <link href="/css/main/main.css" rel="stylesheet">
	    <!-- <link href="//maxcdn.bootstrapcdn.com/font-awesome/4.1.0/css/font-awesome.min.css" rel="stylesheet"> -->
	    <script src="https://ajax.googleapis.com/ajax/libs/jquery/1.11.0/jquery.min.js"></script>
	    <script src="/js/bootstrap.min.js"></script>
    </head>
    <body>
    <div class="af-header-container af-inner-pages-navigation">
	<header>
		<div class="container">
			<div class="row">
				<div class="col-md-1 af-mobile-nav-bar">
					<a href="/" title="Home">
					<img class="hidden-xs hidden-sm img-responsive"
						src="/img/main/logo.png" alt="Apache Flink Logo">
					</a>	
					<div class="row visible-xs">
						<div class="col-xs-3">
						    <a href="/" title="Home">  
							<img class="hidden-x hidden-sm img-responsive"
								src="/img/main/logo.png" alt="Apache Flink Logo">
							</a>	
						</div>
						<div class="col-xs-5"></div>
						<div class="col-xs-4">
							<div class="af-mobile-btn">
								<span class="glyphicon glyphicon-plus"></span>
							</div>
						</div>
					</div>
				</div>
				<!-- Navigation -->
				<div class="col-md-11">
					<nav class="af-main-nav" role="navigation">
						<ul>
							<li><a href="#" class="af-nav-links">Quickstart
									<b class="caret"></b>
							</a>
								<ul class="af-dropdown-menu">
									<li><a href="/docs/0.7-incubating/setup_quickstart.html">Setup
											Flink</a></li>
									<li><a
										href="/docs/0.7-incubating/java_api_quickstart.html">Java
											API</a></li>
									<li><a
										href="/docs/0.7-incubating/scala_api_quickstart.html">Scala
											API</a></li>
								</ul></li>
							<li><a href="/downloads.html">Download</a></li>
							<li><a href="/docs/0.7-incubating/faq.html">FAQ</a></li>
							<li><a href="#" class="af-nav-links">Documentation <b
									class="caret"></b></a>
								<ul class="af-dropdown-menu">
									<li class="af-separator">Current Stable:</li>
									<li></li>
									<li><a href="/docs/0.7-incubating/">0.7.0-incubating</a></li>
									<li><a href="/docs/0.7-incubating/api/java">0.7.0-incubating
											Javadocs</a></li>
									<li><a
										href="/docs/0.7-incubating/api/scala/index.html#org.apache.flink.api.scala.package">0.7.0-incubating
											Scaladocs</a></li>
									<li class="divider"></li>
									<li class="af-separator">Previous:</li>
									<li></li>
									<li><a href="/docs/0.6-incubating/">0.6-incubating</a></li>
									<li><a href="/docs/0.6-incubating/api/java">0.6-incubating
											Javadocs</a></li>
								</ul></li>
							<li><a href="#" class="af-nav-links">Community <b
									class="caret"></b></a>
								<ul class="af-dropdown-menu">
									<li><a href="/community.html#mailing-lists">Mailing
											Lists</a></li>
									<li><a href="/community.html#issues">Issues</a></li>
									<li><a href="/community.html#team">Team</a></li>
									<li class="divider"></li>
									<li><a href="/how-to-contribute.html">How To
											Contribute</a></li>
									<li><a href="/coding_guidelines.html">Coding
											Guidelines</a></li>
								</ul></li>
							<li><a href="#" class="af-nav-links">Project <b
									class="caret"></b></a>
								<ul class="af-dropdown-menu">
									<li><a href="/material.html">Material</a></li>
									<li><a href="http://www.apache.org/">Apache Software
											Foundation <span class="glyphicon glyphicon-new-window"></span>
									</a></li>
									<li><a
										href="https://cwiki.apache.org/confluence/display/FLINK">Wiki
											<span class="glyphicon glyphicon-new-window"></span>
									</a></li>
									<li><a
										href="https://wiki.apache.org/incubator/StratosphereProposal">Incubator
											Proposal <span class="glyphicon glyphicon-new-window"></span>
									</a></li>
									<li><a href="http://www.apache.org/licenses/LICENSE-2.0">License
											<span class="glyphicon glyphicon-new-window"></span>
									</a></li>
									<li><a href="https://github.com/apache/incubator-flink">Source
											Code <span class="glyphicon glyphicon-new-window"></span>
									</a></li>
								</ul></li>
							<li><a href="/blog/index.html" class="">Blog</a></li>
						</ul>
					</nav>
				</div>
			</div>
		</div>
	</header>
</div>


    <div style="padding-top:120px" class="container">
        <div class="container">
    <div class="row">
		<div class="col-md-2"></div>
		<div class="col-md-8">
			<article>
				<h2>Hadoop Compatibility in Flink</h2>
				    <p class="meta">18 Nov 2014</p>
				<div>
				    <p><a href="http://hadoop.apache.org">Apache Hadoop</a> is an industry standard for scalable analytical data processing. Many data analysis applications have been implemented as Hadoop MapReduce jobs and run in clusters around the world. Apache Flink can be an alternative to MapReduce and improves it in many dimensions. Among other features, Flink provides much better performance and offers APIs in Java and Scala, which are very easy to use. Similar to Hadoop, Flink’s APIs provide interfaces for Mapper and Reducer functions, as well as Input- and OutputFormats along with many more operators. While being conceptually equivalent, Hadoop’s MapReduce and Flink’s interfaces for these functions are unfortunately not source compatible.</p>

<h2 id="flink’s-hadoop-compatibility-package">Flink’s Hadoop Compatibility Package</h2>

<p><center>
<img src="/img/blog/hcompat-logos.png" style="width:30%;margin:15px">
</center></p>

<p>To close this gap, Flink provides a Hadoop Compatibility package to wrap functions implemented against Hadoop’s MapReduce interfaces and embed them in Flink programs. This package was developed as part of a <a href="https://developers.google.com/open-source/soc/">Google Summer of Code</a> 2014 project. </p>

<p>With the Hadoop Compatibility package, you can reuse all your Hadoop</p>

<ul>
<li><code>InputFormats</code> (mapred and mapreduce APIs)</li>
<li><code>OutputFormats</code> (mapred and mapreduce APIs)</li>
<li><code>Mappers</code> (mapred API)</li>
<li><code>Reducers</code> (mapred API)</li>
</ul>

<p>in Flink programs without changing a line of code. Moreover, Flink also natively supports all Hadoop data types (<code>Writables</code> and <code>WritableComparable</code>).</p>

<p>The following code snippet shows a simple Flink WordCount program that solely uses Hadoop data types, InputFormat, OutputFormat, Mapper, and Reducer functions. </p>
<div class="highlight"><pre><code class="language-java" data-lang="java"><span class="c1">// Definition of Hadoop Mapper function</span>
<span class="kd">public</span> <span class="kd">class</span> <span class="nc">Tokenizer</span> <span class="kd">implements</span> <span class="n">Mapper</span><span class="o">&lt;</span><span class="n">LongWritable</span><span class="o">,</span> <span class="n">Text</span><span class="o">,</span> <span class="n">Text</span><span class="o">,</span> <span class="n">LongWritable</span><span class="o">&gt;</span> <span class="o">{</span> <span class="o">...</span> <span class="o">}</span>
<span class="c1">// Definition of Hadoop Reducer function</span>
<span class="kd">public</span> <span class="kd">class</span> <span class="nc">Counter</span> <span class="kd">implements</span> <span class="n">Reducer</span><span class="o">&lt;</span><span class="n">Text</span><span class="o">,</span> <span class="n">LongWritable</span><span class="o">,</span> <span class="n">Text</span><span class="o">,</span> <span class="n">LongWritable</span><span class="o">&gt;</span> <span class="o">{</span> <span class="o">...</span> <span class="o">}</span>

<span class="kd">public</span> <span class="kd">static</span> <span class="kt">void</span> <span class="nf">main</span><span class="o">(</span><span class="n">String</span><span class="o">[]</span> <span class="n">args</span><span class="o">)</span> <span class="o">{</span>
  <span class="kd">final</span> <span class="n">String</span> <span class="n">inputPath</span> <span class="o">=</span> <span class="n">args</span><span class="o">[</span><span class="mi">0</span><span class="o">];</span>
  <span class="kd">final</span> <span class="n">String</span> <span class="n">outputPath</span> <span class="o">=</span> <span class="n">args</span><span class="o">[</span><span class="mi">1</span><span class="o">];</span>

  <span class="kd">final</span> <span class="n">ExecutionEnvironment</span> <span class="n">env</span> <span class="o">=</span> <span class="n">ExecutionEnvironment</span><span class="o">.</span><span class="na">getExecutionEnvironment</span><span class="o">();</span>

  <span class="c1">// Setup Hadoop’s TextInputFormat</span>
  <span class="n">HadoopInputFormat</span><span class="o">&lt;</span><span class="n">LongWritable</span><span class="o">,</span> <span class="n">Text</span><span class="o">&gt;</span> <span class="n">hadoopInputFormat</span> <span class="o">=</span> 
      <span class="k">new</span> <span class="n">HadoopInputFormat</span><span class="o">&lt;</span><span class="n">LongWritable</span><span class="o">,</span> <span class="n">Text</span><span class="o">&gt;(</span>
        <span class="k">new</span> <span class="nf">TextInputFormat</span><span class="o">(),</span> <span class="n">LongWritable</span><span class="o">.</span><span class="na">class</span><span class="o">,</span> <span class="n">Text</span><span class="o">.</span><span class="na">class</span><span class="o">,</span> <span class="k">new</span> <span class="nf">JobConf</span><span class="o">());</span>
  <span class="n">TextInputFormat</span><span class="o">.</span><span class="na">addInputPath</span><span class="o">(</span><span class="n">hadoopInputFormat</span><span class="o">.</span><span class="na">getJobConf</span><span class="o">(),</span> <span class="k">new</span> <span class="nf">Path</span><span class="o">(</span><span class="n">inputPath</span><span class="o">));</span>

  <span class="c1">// Read a DataSet with the Hadoop InputFormat</span>
  <span class="n">DataSet</span><span class="o">&lt;</span><span class="n">Tuple2</span><span class="o">&lt;</span><span class="n">LongWritable</span><span class="o">,</span> <span class="n">Text</span><span class="o">&gt;&gt;</span> <span class="n">text</span> <span class="o">=</span> <span class="n">env</span><span class="o">.</span><span class="na">createInput</span><span class="o">(</span><span class="n">hadoopInputFormat</span><span class="o">);</span>
  <span class="n">DataSet</span><span class="o">&lt;</span><span class="n">Tuple2</span><span class="o">&lt;</span><span class="n">Text</span><span class="o">,</span> <span class="n">LongWritable</span><span class="o">&gt;&gt;</span> <span class="n">words</span> <span class="o">=</span> <span class="n">text</span>
    <span class="c1">// Wrap Tokenizer Mapper function</span>
    <span class="o">.</span><span class="na">flatMap</span><span class="o">(</span><span class="k">new</span> <span class="n">HadoopMapFunction</span><span class="o">&lt;</span><span class="n">LongWritable</span><span class="o">,</span> <span class="n">Text</span><span class="o">,</span> <span class="n">Text</span><span class="o">,</span> <span class="n">LongWritable</span><span class="o">&gt;(</span><span class="k">new</span> <span class="nf">Tokenizer</span><span class="o">()))</span>
    <span class="o">.</span><span class="na">groupBy</span><span class="o">(</span><span class="mi">0</span><span class="o">)</span>
    <span class="c1">// Wrap Counter Reducer function (used as Reducer and Combiner)</span>
    <span class="o">.</span><span class="na">reduceGroup</span><span class="o">(</span><span class="k">new</span> <span class="n">HadoopReduceCombineFunction</span><span class="o">&lt;</span><span class="n">Text</span><span class="o">,</span> <span class="n">LongWritable</span><span class="o">,</span> <span class="n">Text</span><span class="o">,</span> <span class="n">LongWritable</span><span class="o">&gt;(</span>
      <span class="k">new</span> <span class="nf">Counter</span><span class="o">(),</span> <span class="k">new</span> <span class="nf">Counter</span><span class="o">()));</span>

  <span class="c1">// Setup Hadoop’s TextOutputFormat</span>
  <span class="n">HadoopOutputFormat</span><span class="o">&lt;</span><span class="n">Text</span><span class="o">,</span> <span class="n">LongWritable</span><span class="o">&gt;</span> <span class="n">hadoopOutputFormat</span> <span class="o">=</span> 
    <span class="k">new</span> <span class="n">HadoopOutputFormat</span><span class="o">&lt;</span><span class="n">Text</span><span class="o">,</span> <span class="n">LongWritable</span><span class="o">&gt;(</span>
      <span class="k">new</span> <span class="n">TextOutputFormat</span><span class="o">&lt;</span><span class="n">Text</span><span class="o">,</span> <span class="n">LongWritable</span><span class="o">&gt;(),</span> <span class="k">new</span> <span class="nf">JobConf</span><span class="o">());</span>
  <span class="n">hadoopOutputFormat</span><span class="o">.</span><span class="na">getJobConf</span><span class="o">().</span><span class="na">set</span><span class="o">(</span><span class="s">&quot;mapred.textoutputformat.separator&quot;</span><span class="o">,</span> <span class="s">&quot; &quot;</span><span class="o">);</span>
  <span class="n">TextOutputFormat</span><span class="o">.</span><span class="na">setOutputPath</span><span class="o">(</span><span class="n">hadoopOutputFormat</span><span class="o">.</span><span class="na">getJobConf</span><span class="o">(),</span> <span class="k">new</span> <span class="nf">Path</span><span class="o">(</span><span class="n">outputPath</span><span class="o">));</span>

  <span class="c1">// Output &amp; Execute</span>
  <span class="n">words</span><span class="o">.</span><span class="na">output</span><span class="o">(</span><span class="n">hadoopOutputFormat</span><span class="o">);</span>
  <span class="n">env</span><span class="o">.</span><span class="na">execute</span><span class="o">(</span><span class="s">&quot;Hadoop Compat WordCount&quot;</span><span class="o">);</span>
<span class="o">}</span>
</code></pre></div>
<p>As you can see, Flink represents Hadoop key-value pairs as <code>Tuple2&lt;key, value&gt;</code> tuples. Note, that the program uses Flink’s <code>groupBy()</code> transformation to group data on the key field (field 0 of the <code>Tuple2&lt;key, value&gt;</code>) before it is given to the Reducer function. At the moment, the compatibility package does not evaluate custom Hadoop partitioners, sorting comparators, or grouping comparators.</p>

<p>Hadoop functions can be used at any position within a Flink program and of course also be mixed with native Flink functions. This means that instead of assembling a workflow of Hadoop jobs in an external driver method or using a workflow scheduler such as <a href="http://oozie.apache.org">Apache Oozie</a>, you can implement an arbitrary complex Flink program consisting of multiple Hadoop Input- and OutputFormats, Mapper and Reducer functions. When executing such a Flink program, data will be pipelined between your Hadoop functions and will not be written to HDFS just for the purpose of data exchange.</p>

<p><center>
<img src="/img/blog/hcompat-flow.png" style="width:100%;margin:15px">
</center></p>

<h2 id="what-comes-next?">What comes next?</h2>

<p>While the Hadoop compatibility package is already very useful, we are currently working on a dedicated Hadoop Job operation to embed and execute Hadoop jobs as a whole in Flink programs, including their custom partitioning, sorting, and grouping code. With this feature, you will be able to chain multiple Hadoop jobs, mix them with Flink functions, and other operations such as <a href="/docs/0.7-incubating/spargel_guide.html">Spargel</a> operations (Pregel/Giraph-style jobs).</p>

<h2 id="summary">Summary</h2>

<p>Flink lets you reuse a lot of the code you wrote for Hadoop MapReduce, including all data types, all Input- and OutputFormats, and Mapper and Reducers of the mapred-API. Hadoop functions can be used within Flink programs and mixed with all other Flink functions. Due to Flink’s pipelined execution, Hadoop functions can arbitrarily be assembled without data exchange via HDFS. Moreover, the Flink community is currently working on a dedicated Hadoop Job operation to supporting the execution of Hadoop jobs as a whole.</p>

<p>If you want to use Flink’s Hadoop compatibility package checkout our <a href="/docs/0.7-incubating/hadoop_compatibility.html">documentation</a>.</p>

<p><br>
<small>Written by Fabian Hueske (<a href="https://twitter.com/fhueske">@fhueske</a>).</small></p>

				</div>
			</article>
		</div>
		<div class="col-md-2"></div>
	</div>
	<div class="row" style="padding-top:30px">
		<div class="col-md-2"></div>
		<div class="col-md-8">
		    <div id="disqus_thread"></div>
		    <script type="text/javascript">
		        /* * * CONFIGURATION VARIABLES: EDIT BEFORE PASTING INTO YOUR WEBPAGE * * */
		        var disqus_shortname = 'stratosphere-eu'; // required: replace example with your forum shortname

		        /* * * DON'T EDIT BELOW THIS LINE * * */
		        (function() {
		            var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
		            dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
		            (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
		        })();
		    </script>
		    <noscript>Please enable JavaScript to view the <a href="http://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
		    <a href="http://disqus.com" class="dsq-brlink">comments powered by <span class="logo-disqus">Disqus</span></a>			    
		</div>
		<div class="col-md-2"></div>
	</div>
</div>

    </div>
    <section id="af-upfooter" class="af-section">
	<div class="container">
		<p>Apache Flink is an effort undergoing incubation at The Apache
			Software Foundation (ASF), sponsored by the Apache Incubator PMC.
			Incubation is required of all newly accepted projects until a further
			review indicates that the infrastructure, communications, and
			decision making process have stabilized in a manner consistent with
			other successful ASF projects. While incubation status is not
			necessarily a reflection of the completeness or stability of the
			code, it does indicate that the project has yet to be fully endorsed
			by the ASF.</p>
		<a href="http://incubator.apache.org"> <img class="img-responsive"
			src="/img/main/apache-incubator-logo.png" alt="Apache Flink" />
		</a>
		<p class="text-center">
			<a href="/privacy-policy.html" title="Privacy Policy"
				class="af-privacy-policy">Privacy Policy</a>
		</p>
	</div>
</section>

<footer id="af-footer">
	<div class="container">
		<div class="row">
			<div class="col-md-3">
				<h3>Documentation</h3>
				<ul class="af-footer-menu">
					<li><a href="/docs/0.6-incubating/">0.6 Incubating</a></li>
					<li><a href="/docs/0.6-incubating/api/java/">0.6
							Incubating Javadocs</a></li>
					<li><a href="/docs/0.7-incubating/">0.7 Incubating</a></li>
					<li><a href="/docs/0.7-incubating/api/java/">0.7
							Incubating Javadocs</a></li>
					<li><a
						href="/docs/0.7-incubating/api/scala/index.html#org.apache.flink.api.scala.package">0.7
							Incubating Scaladocs</a></li>
				</ul>
			</div>
			<div class="col-md-3">
				<h3>Community</h3>
				<ul class="af-footer-menu">
					<li><a href="/community.html#mailing-lists">Mailing Lists</a></li>
					<li><a href="https://issues.apache.org/jira/browse/FLINK"
						target="blank">Issues <span
							class="glyphicon glyphicon-new-window"></span></a></li>
					<li><a href="/community.html#team">Team</a></li>
					<li><a href="/how-to-contribute.html">How to contribute</a></li>
					<li><a href="/coding_guidelines.html">Coding Guidelines</a></li>
				</ul>
			</div>
			<div class="col-md-3">
				<h3>ASF</h3>
				<ul class="af-footer-menu">
					<li><a href="http://www.apache.org/" target="blank">Apache
							Software foundation <span class="glyphicon glyphicon-new-window"></span>
					</a></li>
					<li><a
						href="http://www.apache.org/foundation/how-it-works.html"
						target="blank">How it works <span
							class="glyphicon glyphicon-new-window"></span></a></li>
					<li><a href="http://www.apache.org/foundation/thanks.html"
						target="blank">Thanks <span
							class="glyphicon glyphicon-new-window"></span></a></li>
					<li><a
						href="http://www.apache.org/foundation/sponsorship.html"
						target="blank">Become a sponsor <span
							class="glyphicon glyphicon-new-window"></span></a></li>
					<li><a href="http://incubator.apache.org/projects/flink.html"
						target="blank">Incubation status page <span
							class="glyphicon glyphicon-new-window"></span></a></li>
				</ul>
			</div>
			<div class="col-md-3">
				<h3>Project</h3>
				<ul class="af-footer-menu">
					<li><a href="/material.html" target="blank">Material <span
							class="glyphicon glyphicon-new-window"></span></a></li>
					<li><a
						href="https://cwiki.apache.org/confluence/display/FLINK"
						target="blank">Wiki <span
							class="glyphicon glyphicon-new-window"></span></a></li>
					<li><a
						href="https://wiki.apache.org/incubator/StratosphereProposal"
						target="blank">Incubator proposal <span
							class="glyphicon glyphicon-new-window"></span></a></li>
					<li><a href="http://www.apache.org/licenses/LICENSE-2.0"
						target="blank">License <span
							class="glyphicon glyphicon-new-window"></span></a></li>
					<li><a href="https://github.com/apache/incubator-flink"
						target="blank">Source code <span
							class="glyphicon glyphicon-new-window"></span></a></li>
				</ul>
			</div>
		</div>
	</div>
	<div class="af-footer-bar">
		<div class="container">
			<div class="row">
				<div class="col-md-6">
				  Copyright &copy 2014-2015, <a href="http://www.apache.org">The Apache Software Foundation</a>. All Rights Reserved.
				</div>
				<div class="col-md-5 text-right"></div>
			</div>
		</div>
	</div>
</footer>

    <!-- Google Analytics -->
    <script>
      (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
      (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
      m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
      })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

      ga('create', 'UA-52545728-1', 'auto');
      ga('send', 'pageview');
    </script>
    <script src="/js/main/jquery.mobile.events.min.js"></script>
    <script src="/js/main/main.js"></script>
  </body>
</html>
